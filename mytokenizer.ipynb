{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Test Run"
      ],
      "metadata": {
        "id": "5OU4Z4f91hGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_tokenize = \"\"\"Here is some text to tokenize. It is long and not very usefule but does work as a test\"\"\"\n",
        "tokens = text_to_tokenize.encode(\"utf-8\") # raw bytes\n",
        "ids = list(map(int, tokens))"
      ],
      "metadata": {
        "id": "iKnAVWa2nATR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids"
      ],
      "metadata": {
        "id": "Q8F6fOwnmes1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "vocab_size = 276 # the desired final vocabulary size\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens) # copy so we don't destroy the original list\n",
        "\n",
        "merges = {} # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "  stats = get_stats(ids)\n",
        "  if (len(stats) > 0):\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 256 + i\n",
        "    print(f\"merging {pair} into a new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxclx6uHwR2e",
        "outputId": "8798f51f-8566-4b50-f7b7-d0c8f8a72787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (115, 32) into a new token 256\n",
            "merging (32, 116) into a new token 257\n",
            "merging (116, 32) into a new token 258\n",
            "merging (101, 114) into a new token 259\n",
            "merging (101, 32) into a new token 260\n",
            "merging (105, 256) into a new token 261\n",
            "merging (257, 101) into a new token 262\n",
            "merging (257, 111) into a new token 263\n",
            "merging (32, 97) into a new token 264\n",
            "merging (72, 259) into a new token 265\n",
            "merging (265, 260) into a new token 266\n",
            "merging (266, 261) into a new token 267\n",
            "merging (267, 115) into a new token 268\n",
            "merging (268, 111) into a new token 269\n",
            "merging (269, 109) into a new token 270\n",
            "merging (270, 101) into a new token 271\n",
            "merging (271, 262) into a new token 272\n",
            "merging (272, 120) into a new token 273\n",
            "merging (273, 116) into a new token 274\n",
            "merging (274, 263) into a new token 275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le-l3ZrYyJ7R",
        "outputId": "10ae852f-1a4d-44bb-90d4-2a07f56db757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(115, 32): 256,\n",
              " (32, 116): 257,\n",
              " (116, 32): 258,\n",
              " (101, 114): 259,\n",
              " (101, 32): 260,\n",
              " (105, 256): 261,\n",
              " (257, 101): 262,\n",
              " (257, 111): 263,\n",
              " (32, 97): 264,\n",
              " (72, 259): 265,\n",
              " (265, 260): 266,\n",
              " (266, 261): 267,\n",
              " (267, 115): 268,\n",
              " (268, 111): 269,\n",
              " (269, 109): 270,\n",
              " (270, 101): 271,\n",
              " (271, 262): 272,\n",
              " (272, 120): 273,\n",
              " (273, 116): 274,\n",
              " (274, 263): 275}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in merges.items():\n",
        "    vocab[idx] = vocab[p0] + vocab[p1]\n",
        "\n",
        "def decode(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text\n",
        "\n",
        "print(decode([128]))"
      ],
      "metadata": {
        "id": "g3CniSMkpPOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f218432-a5ff-43b7-b718-04eed8eefb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "�\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "print(encode(\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0hquE62pWO3",
        "outputId": "0a6e199a-f503-4d00-9803-860a1510cec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode(\"hello world\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MmKL18Z0tqz",
        "outputId": "a7e6dc33-137b-4eb0-be87-f8bec78f5b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([32, 116])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "W4aLMOP91Dk6",
        "outputId": "c71baee1-551b-415b-b782-d1fbbd53661d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = encode(\"at the water park\")\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVRb5nHY0t8P",
        "outputId": "a69c30a1-cfce-4b0d-fd63-bafee3972998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[97, 116, 257, 104, 260, 119, 97, 116, 259, 32, 112, 97, 114, 107]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Run - Tokenize Shakespere"
      ],
      "metadata": {
        "id": "yenL8i0I1UQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the TinyShakespeare dataset\n",
        "!wget -O input.txt https://raw.githubusercontent.com/vvr-rao/my-mini-LLama/main/input_text/input.txt\n",
        "!mkdir -p input_folder\n",
        "!mv input.txt input_folder/\n",
        "\n",
        "# load the dataset\n",
        "with open('./input_folder/input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix_DTbIB1anQ",
        "outputId": "a9a0f779-1625-40b3-a301-051b6adf0964"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-25 10:38:46--  https://raw.githubusercontent.com/vvr-rao/my-mini-LLama/main/input_text/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  5.53MB/s    in 0.2s    \n",
            "\n",
            "2024-05-25 10:38:47 (5.53 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1t4zHS21a0j",
        "outputId": "401dfa8b-f07a-4ea1-bff3-eff8c00fd178"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids"
      ],
      "metadata": {
        "id": "oJYMNKb51a3z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.encode(\"utf-8\") # raw bytes\n",
        "ids = list(map(int, tokens))"
      ],
      "metadata": {
        "id": "BlyAehNX138m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# ---\n",
        "vocab_size = 512 # the desired final vocabulary size\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens) # copy so we don't destroy the original list\n",
        "\n",
        "merges = {} # (int, int) -> int\n",
        "for i in tqdm(range(num_merges)):\n",
        "  stats = get_stats(ids)\n",
        "  if (len(stats) > 0):\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 256 + i\n",
        "    #print(f\"merging {pair} into a new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncHOdqCB149M",
        "outputId": "f95652a0-e6ef-4dc8-dcf1-de3e5e50cdde"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 256/256 [02:00<00:00,  2.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merges"
      ],
      "metadata": {
        "id": "Fl4rc47ZHyTr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "!mkdir -p vocab\n",
        "\n",
        "file_name_merges = f'./vocab/merges.pkl'\n",
        "\n",
        "with open(file_name_merges, 'wb') as f:\n",
        "    pickle.dump(merges, f)"
      ],
      "metadata": {
        "id": "qBvn3lCzH6mC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merges), len(vocab), type(merges), type(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hfv7Kh-3J8z",
        "outputId": "cb3cf5ce-4f7f-479e-f894-c70ba22e0189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 296, dict, dict)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge the vocabulary and save it\n",
        "import pickle\n",
        "\n",
        "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in merges.items():\n",
        "    vocab[idx] = vocab[p0] + vocab[p1]\n",
        "\n",
        "\n",
        "file_name = f'./vocab/vocab.pkl'\n",
        "\n",
        "with open(file_name, 'wb') as f:\n",
        "    pickle.dump(vocab, f)\n",
        "\n"
      ],
      "metadata": {
        "id": "jub__QIA39XA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_name, 'rb') as f:\n",
        "    vocab2 = pickle.load(f)"
      ],
      "metadata": {
        "id": "3ENF0Xgg-4LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ-oSTS-_aDO",
        "outputId": "d2f7a650-99fa-4d06-c4ad-d4d8a0397095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: b'\\x00',\n",
              " 1: b'\\x01',\n",
              " 2: b'\\x02',\n",
              " 3: b'\\x03',\n",
              " 4: b'\\x04',\n",
              " 5: b'\\x05',\n",
              " 6: b'\\x06',\n",
              " 7: b'\\x07',\n",
              " 8: b'\\x08',\n",
              " 9: b'\\t',\n",
              " 10: b'\\n',\n",
              " 11: b'\\x0b',\n",
              " 12: b'\\x0c',\n",
              " 13: b'\\r',\n",
              " 14: b'\\x0e',\n",
              " 15: b'\\x0f',\n",
              " 16: b'\\x10',\n",
              " 17: b'\\x11',\n",
              " 18: b'\\x12',\n",
              " 19: b'\\x13',\n",
              " 20: b'\\x14',\n",
              " 21: b'\\x15',\n",
              " 22: b'\\x16',\n",
              " 23: b'\\x17',\n",
              " 24: b'\\x18',\n",
              " 25: b'\\x19',\n",
              " 26: b'\\x1a',\n",
              " 27: b'\\x1b',\n",
              " 28: b'\\x1c',\n",
              " 29: b'\\x1d',\n",
              " 30: b'\\x1e',\n",
              " 31: b'\\x1f',\n",
              " 32: b' ',\n",
              " 33: b'!',\n",
              " 34: b'\"',\n",
              " 35: b'#',\n",
              " 36: b'$',\n",
              " 37: b'%',\n",
              " 38: b'&',\n",
              " 39: b\"'\",\n",
              " 40: b'(',\n",
              " 41: b')',\n",
              " 42: b'*',\n",
              " 43: b'+',\n",
              " 44: b',',\n",
              " 45: b'-',\n",
              " 46: b'.',\n",
              " 47: b'/',\n",
              " 48: b'0',\n",
              " 49: b'1',\n",
              " 50: b'2',\n",
              " 51: b'3',\n",
              " 52: b'4',\n",
              " 53: b'5',\n",
              " 54: b'6',\n",
              " 55: b'7',\n",
              " 56: b'8',\n",
              " 57: b'9',\n",
              " 58: b':',\n",
              " 59: b';',\n",
              " 60: b'<',\n",
              " 61: b'=',\n",
              " 62: b'>',\n",
              " 63: b'?',\n",
              " 64: b'@',\n",
              " 65: b'A',\n",
              " 66: b'B',\n",
              " 67: b'C',\n",
              " 68: b'D',\n",
              " 69: b'E',\n",
              " 70: b'F',\n",
              " 71: b'G',\n",
              " 72: b'H',\n",
              " 73: b'I',\n",
              " 74: b'J',\n",
              " 75: b'K',\n",
              " 76: b'L',\n",
              " 77: b'M',\n",
              " 78: b'N',\n",
              " 79: b'O',\n",
              " 80: b'P',\n",
              " 81: b'Q',\n",
              " 82: b'R',\n",
              " 83: b'S',\n",
              " 84: b'T',\n",
              " 85: b'U',\n",
              " 86: b'V',\n",
              " 87: b'W',\n",
              " 88: b'X',\n",
              " 89: b'Y',\n",
              " 90: b'Z',\n",
              " 91: b'[',\n",
              " 92: b'\\\\',\n",
              " 93: b']',\n",
              " 94: b'^',\n",
              " 95: b'_',\n",
              " 96: b'`',\n",
              " 97: b'a',\n",
              " 98: b'b',\n",
              " 99: b'c',\n",
              " 100: b'd',\n",
              " 101: b'e',\n",
              " 102: b'f',\n",
              " 103: b'g',\n",
              " 104: b'h',\n",
              " 105: b'i',\n",
              " 106: b'j',\n",
              " 107: b'k',\n",
              " 108: b'l',\n",
              " 109: b'm',\n",
              " 110: b'n',\n",
              " 111: b'o',\n",
              " 112: b'p',\n",
              " 113: b'q',\n",
              " 114: b'r',\n",
              " 115: b's',\n",
              " 116: b't',\n",
              " 117: b'u',\n",
              " 118: b'v',\n",
              " 119: b'w',\n",
              " 120: b'x',\n",
              " 121: b'y',\n",
              " 122: b'z',\n",
              " 123: b'{',\n",
              " 124: b'|',\n",
              " 125: b'}',\n",
              " 126: b'~',\n",
              " 127: b'\\x7f',\n",
              " 128: b'\\x80',\n",
              " 129: b'\\x81',\n",
              " 130: b'\\x82',\n",
              " 131: b'\\x83',\n",
              " 132: b'\\x84',\n",
              " 133: b'\\x85',\n",
              " 134: b'\\x86',\n",
              " 135: b'\\x87',\n",
              " 136: b'\\x88',\n",
              " 137: b'\\x89',\n",
              " 138: b'\\x8a',\n",
              " 139: b'\\x8b',\n",
              " 140: b'\\x8c',\n",
              " 141: b'\\x8d',\n",
              " 142: b'\\x8e',\n",
              " 143: b'\\x8f',\n",
              " 144: b'\\x90',\n",
              " 145: b'\\x91',\n",
              " 146: b'\\x92',\n",
              " 147: b'\\x93',\n",
              " 148: b'\\x94',\n",
              " 149: b'\\x95',\n",
              " 150: b'\\x96',\n",
              " 151: b'\\x97',\n",
              " 152: b'\\x98',\n",
              " 153: b'\\x99',\n",
              " 154: b'\\x9a',\n",
              " 155: b'\\x9b',\n",
              " 156: b'\\x9c',\n",
              " 157: b'\\x9d',\n",
              " 158: b'\\x9e',\n",
              " 159: b'\\x9f',\n",
              " 160: b'\\xa0',\n",
              " 161: b'\\xa1',\n",
              " 162: b'\\xa2',\n",
              " 163: b'\\xa3',\n",
              " 164: b'\\xa4',\n",
              " 165: b'\\xa5',\n",
              " 166: b'\\xa6',\n",
              " 167: b'\\xa7',\n",
              " 168: b'\\xa8',\n",
              " 169: b'\\xa9',\n",
              " 170: b'\\xaa',\n",
              " 171: b'\\xab',\n",
              " 172: b'\\xac',\n",
              " 173: b'\\xad',\n",
              " 174: b'\\xae',\n",
              " 175: b'\\xaf',\n",
              " 176: b'\\xb0',\n",
              " 177: b'\\xb1',\n",
              " 178: b'\\xb2',\n",
              " 179: b'\\xb3',\n",
              " 180: b'\\xb4',\n",
              " 181: b'\\xb5',\n",
              " 182: b'\\xb6',\n",
              " 183: b'\\xb7',\n",
              " 184: b'\\xb8',\n",
              " 185: b'\\xb9',\n",
              " 186: b'\\xba',\n",
              " 187: b'\\xbb',\n",
              " 188: b'\\xbc',\n",
              " 189: b'\\xbd',\n",
              " 190: b'\\xbe',\n",
              " 191: b'\\xbf',\n",
              " 192: b'\\xc0',\n",
              " 193: b'\\xc1',\n",
              " 194: b'\\xc2',\n",
              " 195: b'\\xc3',\n",
              " 196: b'\\xc4',\n",
              " 197: b'\\xc5',\n",
              " 198: b'\\xc6',\n",
              " 199: b'\\xc7',\n",
              " 200: b'\\xc8',\n",
              " 201: b'\\xc9',\n",
              " 202: b'\\xca',\n",
              " 203: b'\\xcb',\n",
              " 204: b'\\xcc',\n",
              " 205: b'\\xcd',\n",
              " 206: b'\\xce',\n",
              " 207: b'\\xcf',\n",
              " 208: b'\\xd0',\n",
              " 209: b'\\xd1',\n",
              " 210: b'\\xd2',\n",
              " 211: b'\\xd3',\n",
              " 212: b'\\xd4',\n",
              " 213: b'\\xd5',\n",
              " 214: b'\\xd6',\n",
              " 215: b'\\xd7',\n",
              " 216: b'\\xd8',\n",
              " 217: b'\\xd9',\n",
              " 218: b'\\xda',\n",
              " 219: b'\\xdb',\n",
              " 220: b'\\xdc',\n",
              " 221: b'\\xdd',\n",
              " 222: b'\\xde',\n",
              " 223: b'\\xdf',\n",
              " 224: b'\\xe0',\n",
              " 225: b'\\xe1',\n",
              " 226: b'\\xe2',\n",
              " 227: b'\\xe3',\n",
              " 228: b'\\xe4',\n",
              " 229: b'\\xe5',\n",
              " 230: b'\\xe6',\n",
              " 231: b'\\xe7',\n",
              " 232: b'\\xe8',\n",
              " 233: b'\\xe9',\n",
              " 234: b'\\xea',\n",
              " 235: b'\\xeb',\n",
              " 236: b'\\xec',\n",
              " 237: b'\\xed',\n",
              " 238: b'\\xee',\n",
              " 239: b'\\xef',\n",
              " 240: b'\\xf0',\n",
              " 241: b'\\xf1',\n",
              " 242: b'\\xf2',\n",
              " 243: b'\\xf3',\n",
              " 244: b'\\xf4',\n",
              " 245: b'\\xf5',\n",
              " 246: b'\\xf6',\n",
              " 247: b'\\xf7',\n",
              " 248: b'\\xf8',\n",
              " 249: b'\\xf9',\n",
              " 250: b'\\xfa',\n",
              " 251: b'\\xfb',\n",
              " 252: b'\\xfc',\n",
              " 253: b'\\xfd',\n",
              " 254: b'\\xfe',\n",
              " 255: b'\\xff',\n",
              " 256: b'e ',\n",
              " 257: b'th',\n",
              " 258: b't ',\n",
              " 259: b's ',\n",
              " 260: b'd ',\n",
              " 261: b', ',\n",
              " 262: b'ou',\n",
              " 263: b'er',\n",
              " 264: b'in',\n",
              " 265: b'y ',\n",
              " 266: b'an',\n",
              " 267: b':\\n',\n",
              " 268: b'or',\n",
              " 269: b'o ',\n",
              " 270: b'en',\n",
              " 271: b'\\n\\n',\n",
              " 272: b'ar',\n",
              " 273: b' th',\n",
              " 274: b'on',\n",
              " 275: b'll',\n",
              " 276: b'ha',\n",
              " 277: b',\\n',\n",
              " 278: b'.\\n\\n',\n",
              " 279: b'is ',\n",
              " 280: b'es',\n",
              " 281: b'you',\n",
              " 282: b' s',\n",
              " 283: b'to ',\n",
              " 284: b'and ',\n",
              " 285: b'ow',\n",
              " 286: b'ea',\n",
              " 287: b' m',\n",
              " 288: b' w',\n",
              " 289: b'of',\n",
              " 290: b' h',\n",
              " 291: b'ing',\n",
              " 292: b'om',\n",
              " 293: b' a',\n",
              " 294: b'ch',\n",
              " 295: b'the '}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decode(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab2[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text"
      ],
      "metadata": {
        "id": "Jg_w6GvA2Ni1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "KtFAgxIL2QzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode([105, 259])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r147Rtx13qVW",
        "outputId": "b7a1b6cd-5d63-4117-c3e4-ef71cb830d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(encode(\"Wherefore art thou Romeo!! and wherefore are the tater tots?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QTN48ptQ5S6q",
        "outputId": "d4e39584-0980-4375-e7dc-f71c48787322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wherefore art thou Romeo!! and wherefore are the tater tots?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}