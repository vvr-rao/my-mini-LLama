{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Test Run"
      ],
      "metadata": {
        "id": "5OU4Z4f91hGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_tokenize = \"\"\"Here is some text to tokenize. It is long and not very usefule but does work as a test\"\"\"\n",
        "tokens = text_to_tokenize.encode(\"utf-8\") # raw bytes\n",
        "ids = list(map(int, tokens))"
      ],
      "metadata": {
        "id": "iKnAVWa2nATR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids"
      ],
      "metadata": {
        "id": "Q8F6fOwnmes1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "vocab_size = 276 # the desired final vocabulary size\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens) # copy so we don't destroy the original list\n",
        "\n",
        "merges = {} # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "  stats = get_stats(ids)\n",
        "  if (len(stats) > 0):\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 256 + i\n",
        "    print(f\"merging {pair} into a new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxclx6uHwR2e",
        "outputId": "55763544-bd1c-4677-ef59-e6276c45655a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (115, 32) into a new token 256\n",
            "merging (32, 116) into a new token 257\n",
            "merging (116, 32) into a new token 258\n",
            "merging (101, 114) into a new token 259\n",
            "merging (101, 32) into a new token 260\n",
            "merging (105, 256) into a new token 261\n",
            "merging (257, 101) into a new token 262\n",
            "merging (257, 111) into a new token 263\n",
            "merging (32, 97) into a new token 264\n",
            "merging (72, 259) into a new token 265\n",
            "merging (265, 260) into a new token 266\n",
            "merging (266, 261) into a new token 267\n",
            "merging (267, 115) into a new token 268\n",
            "merging (268, 111) into a new token 269\n",
            "merging (269, 109) into a new token 270\n",
            "merging (270, 101) into a new token 271\n",
            "merging (271, 262) into a new token 272\n",
            "merging (272, 120) into a new token 273\n",
            "merging (273, 116) into a new token 274\n",
            "merging (274, 263) into a new token 275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le-l3ZrYyJ7R",
        "outputId": "8c585ee7-9693-4c2b-931f-68570be874ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(115, 32): 256,\n",
              " (32, 116): 257,\n",
              " (116, 32): 258,\n",
              " (101, 114): 259,\n",
              " (101, 32): 260,\n",
              " (105, 256): 261,\n",
              " (257, 101): 262,\n",
              " (257, 111): 263,\n",
              " (32, 97): 264,\n",
              " (72, 259): 265,\n",
              " (265, 260): 266,\n",
              " (266, 261): 267,\n",
              " (267, 115): 268,\n",
              " (268, 111): 269,\n",
              " (269, 109): 270,\n",
              " (270, 101): 271,\n",
              " (271, 262): 272,\n",
              " (272, 120): 273,\n",
              " (273, 116): 274,\n",
              " (274, 263): 275}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in merges.items():\n",
        "    vocab[idx] = vocab[p0] + vocab[p1]\n",
        "\n",
        "def decode(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text\n",
        "\n",
        "print(decode([128]))"
      ],
      "metadata": {
        "id": "g3CniSMkpPOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d11bea3-c9bc-41fd-8545-6db01a04c0b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï¿½\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "print(encode(\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0hquE62pWO3",
        "outputId": "5eee9591-851c-4940-e05c-5b219433ac1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode(\"hello world\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MmKL18Z0tqz",
        "outputId": "85831617-d26e-4d48-e2c5-eb956654a166"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([32, 116])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "W4aLMOP91Dk6",
        "outputId": "121990ae-7cc4-4890-be06-16dcdf7105cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = encode(\"at the water park\")\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVRb5nHY0t8P",
        "outputId": "cbbf72d9-8d49-449a-c568-0064aab71a82"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[97, 116, 257, 104, 260, 119, 97, 116, 259, 32, 112, 97, 114, 107]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Run - Tokenize Shakespere"
      ],
      "metadata": {
        "id": "yenL8i0I1UQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the TinyShakespeare dataset\n",
        "!wget -O input.txt https://raw.githubusercontent.com/vvr-rao/my-mini-LLama/main/input_text/input.txt\n",
        "!mkdir -p input_folder\n",
        "!mv input.txt input_folder/\n",
        "\n",
        "# load the dataset\n",
        "with open('./input_folder/input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix_DTbIB1anQ",
        "outputId": "a29fcf75-de53-412b-8dd6-8deade773f9a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-25 08:25:58--  https://raw.githubusercontent.com/vvr-rao/my-mini-LLama/main/input_text/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: âinput.txtâ\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-05-25 08:25:59 (16.7 MB/s) - âinput.txtâ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1t4zHS21a0j",
        "outputId": "f6fb02c3-7167-4f6f-e2c4-1d0ce00d3501"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids"
      ],
      "metadata": {
        "id": "oJYMNKb51a3z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.encode(\"utf-8\") # raw bytes\n",
        "ids = list(map(int, tokens))"
      ],
      "metadata": {
        "id": "BlyAehNX138m"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "vocab_size = 296 # the desired final vocabulary size\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens) # copy so we don't destroy the original list\n",
        "\n",
        "merges = {} # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "  stats = get_stats(ids)\n",
        "  if (len(stats) > 0):\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 256 + i\n",
        "    print(f\"merging {pair} into a new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncHOdqCB149M",
        "outputId": "c9fac62d-3747-422f-e300-45f823f704ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (101, 32) into a new token 256\n",
            "merging (116, 104) into a new token 257\n",
            "merging (116, 32) into a new token 258\n",
            "merging (115, 32) into a new token 259\n",
            "merging (100, 32) into a new token 260\n",
            "merging (44, 32) into a new token 261\n",
            "merging (111, 117) into a new token 262\n",
            "merging (101, 114) into a new token 263\n",
            "merging (105, 110) into a new token 264\n",
            "merging (121, 32) into a new token 265\n",
            "merging (97, 110) into a new token 266\n",
            "merging (58, 10) into a new token 267\n",
            "merging (111, 114) into a new token 268\n",
            "merging (111, 32) into a new token 269\n",
            "merging (101, 110) into a new token 270\n",
            "merging (10, 10) into a new token 271\n",
            "merging (97, 114) into a new token 272\n",
            "merging (32, 257) into a new token 273\n",
            "merging (111, 110) into a new token 274\n",
            "merging (108, 108) into a new token 275\n",
            "merging (104, 97) into a new token 276\n",
            "merging (44, 10) into a new token 277\n",
            "merging (46, 271) into a new token 278\n",
            "merging (105, 259) into a new token 279\n",
            "merging (101, 115) into a new token 280\n",
            "merging (121, 262) into a new token 281\n",
            "merging (32, 115) into a new token 282\n",
            "merging (116, 269) into a new token 283\n",
            "merging (266, 260) into a new token 284\n",
            "merging (111, 119) into a new token 285\n",
            "merging (101, 97) into a new token 286\n",
            "merging (32, 109) into a new token 287\n",
            "merging (32, 119) into a new token 288\n",
            "merging (111, 102) into a new token 289\n",
            "merging (32, 104) into a new token 290\n",
            "merging (264, 103) into a new token 291\n",
            "merging (111, 109) into a new token 292\n",
            "merging (32, 97) into a new token 293\n",
            "merging (99, 104) into a new token 294\n",
            "merging (257, 256) into a new token 295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(merges), len(vocab), type(merges), type(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hfv7Kh-3J8z",
        "outputId": "cb3cf5ce-4f7f-479e-f894-c70ba22e0189"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 296, dict, dict)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge the vocabulary and save it\n",
        "import pickle\n",
        "\n",
        "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in merges.items():\n",
        "    vocab[idx] = vocab[p0] + vocab[p1]\n",
        "\n",
        "!mkdir -p vocab\n",
        "file_name = f'./vocab/vocab.pkl'\n",
        "\n",
        "with open(file_name, 'wb') as f:\n",
        "    pickle.dump(vocab, f)"
      ],
      "metadata": {
        "id": "jub__QIA39XA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decode(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text"
      ],
      "metadata": {
        "id": "Jg_w6GvA2Ni1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "KtFAgxIL2QzU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode([105, 259])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r147Rtx13qVW",
        "outputId": "b7a1b6cd-5d63-4117-c3e4-ef71cb830d56"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(encode(\"Wherefore art thou Romeo!! and wherefore are the tater tots?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QTN48ptQ5S6q",
        "outputId": "81d9cc75-368c-44b8-e5be-c544618d1020"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wherefore art thou Romeo!! and wherefore are the tater tots?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}